# -*- coding: utf-8 -*-
"""depression prediction via deep learning

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15_bY908Kc7kajRfiorv2RlKJj-5VPUML
"""

!pip install tensorflow

!pip install keras

! pip install keras-tuner

# Import required packages
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.preprocessing import LabelEncoder,MinMaxScaler

from sklearn.ensemble import RandomForestClassifier

from imblearn.over_sampling import RandomOverSampler
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report,ConfusionMatrixDisplay

import tensorflow as tf
from tensorflow import keras

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LeakyReLU, Dropout, Input
from tensorflow.keras.metrics import Precision, Recall, F1Score

tr_data = pd.read_csv("train.csv")
ts_data = pd.read_csv("test.csv")
sample_sub = pd.read_csv("sample_submission.csv")

tr_data

tr_data.info()

tr_data.shape

ts_data.shape

tr_data.isnull().sum()

"""# **Data Cleaning and EDA**"""

(2/140700)*100

# Dropping negligible missing values from columns Degree,Financial Stress and Dietary Habits
tr_data[tr_data['Degree'].isnull()]

tr_data.dropna(subset=['Degree','Financial Stress','Dietary Habits'],inplace=True)

tr_data.shape

tr_data[(tr_data['Profession'].isnull()) & (tr_data['Working Professional or Student']!='Student')]

(8761/140698)*100

# Dropping Null values from Profession column only for Working Professionals as the percent is close to 6%
# Later,Null values in Profession column for students can be filled with value as 'Student'
tr_data.drop(tr_data[(tr_data['Profession'].isnull()) & (tr_data['Working Professional or Student']!='Student')].index,inplace=True)

tr_data.shape

140698-8761

tr_data['Gender'].value_counts()

tr_data['Age'].value_counts()

tr_data["Working Professional or Student"].value_counts()

tr_data['Profession'].value_counts()

tr_data['Profession'].isnull().sum()

tr_data['Financial Stress'].value_counts()

tr_data['Financial Stress'].isnull().sum()

tr_data['Depression'].value_counts()

tr_data['Sleep Duration'].value_counts()

tr_data["Have you ever had suicidal thoughts ?"].value_counts()

tr_data['Gender'].value_counts()

tr_data['City'].value_counts()

tr_data['Academic Pressure'].value_counts()

tr_data['Work Pressure'].value_counts()

tr_data['CGPA'].value_counts()

tr_data['Study Satisfaction'].value_counts()

tr_data['Job Satisfaction'].value_counts()

tr_data['Dietary Habits'].value_counts()

tr_data['Degree'].value_counts()

tr_data['Work/Study Hours'].value_counts()

tr_data['Have you ever had suicidal thoughts ?'].value_counts()

tr_data['Family History of Mental Illness'].value_counts()

diet=list(tr_data['Dietary Habits'].unique())

diet

tr_data[tr_data['Dietary Habits'].apply(lambda x: x not in ['Healthy','Unhealthy','Moderate'])]
ts_data[ts_data['Dietary Habits'].apply(lambda x: x not in ['Healthy','Unhealthy','Moderate'])]

num_col = tr_data.select_dtypes(exclude="object").columns.to_list()
num_col

tr_data.duplicated().sum()

tr_data['City'].value_counts()

city=tr_data['City'].value_counts()<100
city

[key for key,value in city.items() if value==True ]

profession = tr_data['Profession'].value_counts(normalize=True)<0.003
profession

len([key for key,value in profession.items() if value==True ])

tr_data.isnull().sum()

tr_data.isnull().sum()

tr_data[(tr_data['Academic Pressure'].isnull()) & (tr_data['Working Professional or Student']=='Student')]

tr_data.shape

9/131937 * 100

# Drop rows with Null values in Academic Pressure for Students and the null value percent is close to 0.01
tr_data.drop(tr_data[(tr_data['Academic Pressure'].isnull()) & (tr_data['Working Professional or Student']=='Student')].index,inplace=True)

tr_data.shape

3/131926 *100

tr_data[(tr_data['Work Pressure'].isnull()) & (tr_data['Working Professional or Student']!='Student')]

# Drop rows with Null values in Work Pressure for Working Profrssionals and the null value percent is close to 0.001
tr_data.drop(tr_data[(tr_data['Work Pressure'].isnull()) & (tr_data['Working Professional or Student']!='Student')].index,inplace=True)

tr_data.shape

tr_data.isnull().sum()

tr_data[(tr_data['CGPA'].isnull()) & (tr_data['Working Professional or Student']=='Student')]

tr_data[(tr_data['Study Satisfaction'].isnull()) & (tr_data['Working Professional or Student']=='Student')]

tr_data[(tr_data['Job Satisfaction'].isnull()) & (tr_data['Working Professional or Student']=='Student')]

# Removing rows with null values in columns CGPA and Study Satisfaction for Students as the percents are close to 0.002
tr_data.drop(tr_data[(tr_data['CGPA'].isnull()) & (tr_data['Working Professional or Student']=='Student')].index,inplace=True)
tr_data.drop(tr_data[(tr_data['Study Satisfaction'].isnull()) & (tr_data['Working Professional or Student']=='Student')].index,inplace=True)

tr_data.shape

tr_data.isnull().sum()

tr_data.shape

tr_data.info()

tr_data.describe()

def Grouping_degree(degree,df):
  for i in degree:
    if i.startswith('B') or i=='MBBS' or i=='LLB':
      df['Degree']=df['Degree'].replace(i,'Bachelors')
    elif i.startswith('M') or i=='LLM':
      df['Degree']=df['Degree'].replace(i,'Masters')
    elif i.startswith('P'):
      df['Degree']=df['Degree'].replace(i,'Doctorate')
    else:
      pass
  return df

def clean_data(df):
  # Drop ID and Name columns in the dataframe
  df.drop(['id','Name'],axis = 1, inplace = True)

  # Handling Null values in numerical data columns
  df['Academic Pressure']=df['Academic Pressure'].fillna(0.0)
  df['Work Pressure']=df['Work Pressure'].fillna(0.0)
  df['CGPA']=df['CGPA'].fillna(0.0)
  df['Study Satisfaction']=df['Study Satisfaction'].fillna(0.0)
  df['Job Satisfaction']=df['Job Satisfaction'].fillna(0.0)
  df['Financial Stress']=df['Financial Stress'].fillna(0.0)

  # Clean Dietary Habits
  df['Dietary Habits']= df['Dietary Habits'].apply(lambda x: 'Unhealthy' if x in ['Less than Healthy','No Healthy',
                                                                                  'Less Healthy'] else x)
  df['Dietary Habits']= df['Dietary Habits'].apply(lambda x: 'Healthy' if x == 'More Healthy' else x)
  df['Dietary Habits']= df['Dietary Habits'].apply(lambda x: x if x in ['Healthy','Unhealthy','Moderate']
                                                   else 'Other')

  # Clean City Data - Replace the misspelled City name with correct value and
  # change the names to Other for Cities with less occurances
  city=list(df['City'].unique())
  df['City']=df['City'].replace(['Galesabad','Khaziabad'],'Ghaziabad')
  df['City']=df['City'].replace(['Itheg','Ithal'],'Ithalar')
  df['City']=df['City'].replace(['Tolkata','Molkata'],'Kolkata')
  df['City']=df['City'].replace(['Nalyan','Less than 5 Kalyan'],'Kalyan')
  df['City']=df['City'].replace(['Less Delhi'],'Delhi')

  freq = df['City'].value_counts(normalize=True)
  df['City'] = df['City'].apply(lambda x: x if freq[x] > 0.0001 else 'Other')

  # Sleep duration
  freq = df['Sleep Duration'].value_counts(normalize=True)
  df['Sleep Duration'] = df['Sleep Duration'].apply(lambda x: x if freq[x] > 0.003 else 'Other')

  # Degree
  df['Degree']=df['Degree'].fillna('Other')
  freq = df['Degree'].value_counts(normalize=True)
  df['Degree'] = df['Degree'].apply(lambda x: x if freq[x] > 0.003 else 'Other')
  degree = list(df['Degree'].unique())
  df=Grouping_degree(degree,df)

  # Profession
  df["Profession"] = df.apply(lambda x: "Student" if x["Working Professional or Student"] == "Student"
                              and str(x["Profession"]) == "nan"
                              else x["Profession"], axis = 1)
  df['Profession']=df['Profession'].fillna('Other')
  df['Profession']=df['Profession'].replace('City Manager','Manager')
  df['Profession']=df['Profession'].replace('Dev','Software Engineer')
  df['Profession']=df['Profession'].replace('Medical Doctor','Doctor')
  df['Profession']=df['Profession'].replace('Finanancial Analyst','Financial Analyst')
  freq = df['Profession'].value_counts(normalize=True)
  df['Profession'] = df['Profession'].apply(lambda x: x if freq[x] > 0.003 else 'Other')

  return df

tr_data= clean_data(tr_data)
ts_data = clean_data(ts_data)

tr_data.isnull().sum()

tr_data.info()

ts_data.info()

ts_data.info()

ts_data.isnull().sum()

df_dep=tr_data[tr_data['Depression']==1]
plt.title("Top 10 City with high depression rate")
sns.countplot(x='City', data=df_dep, order=df_dep['City'].value_counts().head(10).index, hue='Gender')
plt.ylabel("Approx. Depressed Persons count")
plt.xticks(rotation=90)
plt.show()

plt.title("Top 10 Professions with high depression rate")
sns.countplot(x='Profession', data=df_dep, order=df_dep['Profession'].value_counts().head(10).index, hue='Gender')
plt.ylabel("Approx. Depressed Persons count")
plt.xticks(rotation=90)
plt.show()

num_col = tr_data.select_dtypes(exclude="object").columns.to_list()

for i in num_col:
  plt.title(f"KDE Plot of {i}")
  sns.kdeplot(tr_data[i])
  plt.show()

tr_data['Age Group'] = pd.cut(tr_data['Age'], bins=[20, 30, 40, 50, 60], labels=['20-30', '30-40', '40-50', '50-60'])
plt.title("Age Vs Depression")
sns.histplot(x='Age Group',hue='Depression',data=tr_data,multiple='stack',shrink =0.5)
plt.show()

plt.title("Gender Vs Depression")
sns.histplot(x='Gender',hue='Depression',data=tr_data,multiple='stack',shrink=0.5)
plt.show()

plt.title("Working Professional or Student Vs Depression")
sns.histplot(x='Working Professional or Student',hue='Depression',data=tr_data,multiple='stack',shrink=0.5)
plt.show()

plt.figure(figsize=(15,5))
plt.title("Box plot of numerical columns")
sns.boxplot(tr_data[num_col])

# Correlation plot for numerical columns
plt.figure(figsize=(15,5))
sns.heatmap(tr_data[num_col].corr(),cmap='coolwarm',annot=True)

# Finding outliers
def get_outliers(df,col):
  Q1 = df[col].quantile(0.25)
  Q3 = df[col].quantile(0.75)
  IQR = Q3 - Q1
  lower_bound = Q1 - 1.5 * IQR
  upper_bound = Q3 + 1.5 * IQR
  outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]
  return outliers

df_acpres=get_outliers(tr_data,'Academic Pressure')
df_acpres['Academic Pressure'].value_counts()

df_cgpa=get_outliers(tr_data,'CGPA')
df_cgpa['CGPA'].value_counts()

df_study = get_outliers(tr_data,'Study Satisfaction')
df_study['Study Satisfaction'].value_counts()

"""Outliers are due to null value imputation. So the outliers need not be taken care."""

# Encoding categorical variables
cat_col = tr_data.select_dtypes(include="object").columns.to_list()
cat_col

for i in cat_col:
  print(tr_data[i].value_counts())
  print("=====================================")

tr_data.duplicated().sum()

# Initialize Label encoder
tr_data['Degree']=tr_data['Degree'].map({'Other' :0,'Class 12':1, "Bachelors" : 2, "Masters":3, "Doctorate":4})
tr_data['Dietary Habits']=tr_data['Dietary Habits'].map({'Other':0, 'Healthy':3, 'Unhealthy':1, 'Moderate':2})

ts_data['Degree']=ts_data['Degree'].map({'Other' :0,'Class 12':1, "Bachelors" : 2, "Masters":3, "Doctorate":4})
ts_data['Dietary Habits']=ts_data['Dietary Habits'].map({'Other':0, 'Healthy':3, 'Unhealthy':1, 'Moderate':2})

le = LabelEncoder()

for i in tr_data.select_dtypes(include="object").columns.to_list():
  tr_data[i] = le.fit_transform(tr_data[i])

ts_data.select_dtypes(include="object").columns.to_list()

ts_data['Family History of Mental Illness'].value_counts()

ts_data['Gender'].value_counts()

tr_data['Gender'].value_counts()

for i in ts_data.select_dtypes(include="object").columns.to_list():

  ts_data[i] = le.fit_transform(ts_data[i])

tr_data

ts_data

tr_data.duplicated().sum()

tr_data.drop_duplicates(inplace=True)

tr_data.duplicated().sum()

tr_data.shape

tr_data

ts_data

tr_data['Dietary Habits'].value_counts()

tr_data['Degree'].value_counts()

tr_data['Family History of Mental Illness'].value_counts()

tr_data["Have you ever had suicidal thoughts ?"].value_counts()

tr_data['Gender'].value_counts()

tr_data['Working Professional or Student'].value_counts()

tr_data['Sleep Duration'].value_counts()

tr_data['City'].value_counts()

tr_data['Profession'].value_counts()

num_col=['Age',
 'Academic Pressure',
 'Work Pressure',
 'CGPA',
 'Study Satisfaction',
 'Job Satisfaction',
 'Work/Study Hours',
 'Financial Stress']

# MinMax scaling of training data
scaler = MinMaxScaler()
tr_data[num_col] = scaler.fit_transform(tr_data[num_col])

# MinMax scaling of testing data
ts_data[num_col] = scaler.transform(ts_data[num_col])

tr_data.drop(['Age Group'],axis=1,inplace=True)
tr_data

ts_data



"""# **Building Model with Keras**"""

# Split data into val and tar
val = tr_data.drop('Depression',axis=1)
tar = tr_data['Depression']

tr, ts, trl, tsl = train_test_split(val, tar, test_size= 0.20, random_state= 42)

val.shape

tar.value_counts()

model = tf.keras.Sequential([
    tf.keras.Input(shape=(17,)),
    tf.keras.layers.Dense(128,activation='relu',),
    tf.keras.layers.Dropout(rate=0.3),
    tf.keras.layers.Dense(64, activation='leaky_relu'),
    tf.keras.layers.Dense(32, activation='tanh'),
    tf.keras.layers.Dense(16, activation='relu'),
    tf.keras.layers.Dropout(rate=0.5),
    tf.keras.layers.Dense(8, activation='relu'),
    tf.keras.layers.Dense(4, activation='relu'),
    tf.keras.layers.Dense(2, activation='relu'),
    tf.keras.layers.Dense(1, activation='sigmoid')
])

model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
              loss='binary_crossentropy',metrics=['accuracy',Precision(name='precision'),
                                                  Recall(name='recall'),F1Score(name='f1_score')])


model.fit(tr, trl, epochs=50,validation_data=(ts,tsl),validation_split=0.2, batch_size=128)

model.summary()

from google.colab import drive
drive.mount('/content/drive')

import os
os.makedirs('/content/drive/MyDrive/Project-5-Predict-depression', exist_ok=True)

model.save('/content/drive/MyDrive/Project-5-Predict-depression/model.keras')

# Using RF claasifier to identify important features
model_01 = RandomForestClassifier(n_estimators= 100, random_state= 42, max_depth= 4,class_weight='balanced')

model_01.fit(val, tar)

# select features based on score threshold

pd.DataFrame({
    "Columns": val.columns,
    "Score": model_01.feature_importances_ * 100
}).sort_values('Score', ascending= False).reset_index(drop= True)

s_col = pd.DataFrame({
    "Columns": val.columns,
    "Score": model_01.feature_importances_ * 100
}).sort_values('Score', ascending= False).head(13)['Columns'].values.tolist()

len(s_col)

s_col

rf_val = val[s_col]
rf_tar = tar

rf_tr, rf_ts, rf_trl, rf_tsl = train_test_split(rf_val, rf_tar, test_size= 0.20, random_state= 66)

rf_val

rf_tar.value_counts()

model_2 = tf.keras.Sequential([
    tf.keras.Input(shape=(13,)),
    tf.keras.layers.Dense(128,activation='relu',),
    tf.keras.layers.Dropout(rate=0.3),
    tf.keras.layers.Dense(64, activation='leaky_relu'),
    tf.keras.layers.Dense(32, activation='tanh'),
    tf.keras.layers.Dense(16, activation='relu'),
    tf.keras.layers.Dropout(rate=0.5),
    tf.keras.layers.Dense(8, activation='relu'),
    tf.keras.layers.Dense(4, activation='relu'),
    tf.keras.layers.Dense(2, activation='relu'),
    tf.keras.layers.Dense(1, activation='sigmoid')
])

model_2.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
              loss='binary_crossentropy',metrics=['accuracy',Precision(name='precision'),
                                                  Recall(name='recall'),F1Score(name='f1_score')])


model_2.fit(rf_tr, rf_trl, epochs=50,validation_data=(rf_ts,rf_tsl),validation_split=0.2, batch_size=128)

model_2.summary()

model_2.save('/content/drive/MyDrive/Project-5-Predict-depression/model_rf.keras')

"""## **Model Validation**"""

# Result for training data
result = model.evaluate(tr,trl)

# Result for testing data
result = model.evaluate(ts,tsl)

# Result with only selected important features for training data
result = model_2.evaluate(rf_tr,rf_trl)

# Result with only selected important features for testing data
result = model_2.evaluate(rf_ts,rf_tsl)

tr_pred = model.predict(tr)
ts_pred = model.predict(ts)

cm=confusion_matrix(trl.tolist(),tr_pred.round().astype(int).flatten().tolist())

ConfusionMatrixDisplay(cm,display_labels=[0,1]).plot(cmap='Blues')

cms=confusion_matrix(tsl,ts_pred.round())
ConfusionMatrixDisplay(cms,display_labels=[0,1]).plot(cmap='Blues')

classification_report(trl,tr_pred.round())

classification_report(tsl,ts_pred.round())

"""# **Predicting Testdata**"""

sample_sub['Depression']

best_model= tf.keras.models.load_model('/content/drive/MyDrive/Project-5-Predict-depression/model.keras')
ts_predict= best_model.predict(ts_data)

ts_predlist=ts_predict.round().astype(int).flatten().tolist()

final_pred=pd.DataFrame({
    'id' : sample_sub['id'],
    'Depression' : ts_predlist
})
final_pred.to_csv('/content/drive/MyDrive/Project-5-Predict-depression/final_predictions.csv',index=False)

pd.read_csv('/content/drive/MyDrive/Project-5-Predict-depression/final_predictions.csv')

sample_sub

ts_actual = sample_sub['Depression'].tolist()
accuracy_score(ts_actual,ts_predlist)

ts_data

"""# **Testing with single entry**"""

data=pd.DataFrame({
    'id' : [2],
    'Name'	: ['Nalini'],
    'Gender': ['Female'],
    'Age' : [23],
    'City' : ['Rajkot'],
    'Working Professional or Student' : ['Student'],
    'Profession' : ['Student'],
    'Academic Pressure': [5.0],
    'Work Pressure': [0.0],
    'CGPA': [6.84],
    'Study Satisfaction':[1.0],
    'Job Satisfaction': [0.0],
    'Sleep Duration': ['More than 8 hours'],
    'Dietary Habits': ['Moderate'],
    'Degree':['BSc'],
    "Have you ever had suicidal thoughts ?": ['Yes'],
    'Work/Study Hours': [10.0],
    'Financial Stress': [4.0],
    'Family History of Mental Illness' : ['No']
})
data

def preprocess(df):
  df = clean_data(df)
  df['Degree']=df['Degree'].map({'Other' :0,'Class 12':1, "Bachelors" : 2, "Masters":3, "Doctorate":4})
  df['Dietary Habits']=df['Dietary Habits'].map({'Other':0, 'Healthy':3, 'Unhealthy':1, 'Moderate':2})
  df['Family History of Mental Illness']=df['Family History of Mental Illness'].map({'No':0,'Yes':1})
  df['Have you ever had suicidal thoughts ?']=df['Have you ever had suicidal thoughts ?'].map({'No':0,'Yes':1})
  df['Working Professional or Student']=df['Working Professional or Student'].map({'Student':0,'Working Professional':1})
  df['Gender']=df['Gender'].map({'Male':1,'Female':0})
  df['Sleep Duration']=df['Sleep Duration'].map({'Less than 5 hours':2,'7-8 hours':1,'More than 8 hours':3,
                                                 '5-6 hours':0,'Other':4})
  df['City']=df['City'].map({'Kalyan':11, 'Patna':21, 'Vasai-Virar':29, 'Kolkata':13, 'Meerut':16, 'Ahmedabad':1,
                             'Visakhapatnam':30, 'Pune':22, 'Ludhiana':15, 'Rajkot':23, 'Srinagar':24, 'Mumbai':17,
                             'Indore':9, 'Surat':25, 'Varanasi':28, 'Agra':0, 'Hyderabad':8, 'Jaipur':10, 'Kanpur':12,
                             'Vadodara':27, 'Lucknow':14, 'Nagpur':18, 'Thane':26, 'Bangalore':2, 'Chennai':4, 'Ghaziabad':7,
                             'Delhi':5, 'Bhopal':3, 'Faridabad':6, 'Nashik':19, 'Other':20})

  df['Profession']= df['Profession'].map({'Student':31, 'Teacher':32, 'Content Writer':7, 'Architect':1, 'Consultant':6,
                                          'HR Manager':17, 'Pharmacist':24, 'Doctor':11, 'Business Analyst':2,
                                          'Entrepreneur':14, 'Chemist':4, 'Financial Analyst':15, 'Chef':3,
                                          'Educational Consultant':12, 'Data Scientist':9, 'Researcher':28, 'Lawyer':19,
                                          'Customer Support':8, 'Marketing Manager':21, 'Pilot':25, 'Travel Consultant':33,
                                          'Plumber':26, 'Sales Executive':29, 'Manager':20, 'Judge':18, 'Electrician':13,
                                          'Software Engineer':30, 'Civil Engineer':5, 'UX/UI:Designer':34, 'Digital Marketer':10,
                                          'Accountant':0, 'Mechanical Engineer':22, 'Graphic Designer':16, 'Research Analyst':27,
                                          'Other':23})



  return df

data_c= preprocess(data)
data_c

num_col=['Age','Academic Pressure','Work Pressure','CGPA','Study Satisfaction','Job Satisfaction','Work/Study Hours',
           'Financial Stress']
# scaler = MinMaxScaler()
data_c[num_col] = scaler.transform(data_c[num_col])

data_c

data_c

data_c.values

new_sample_tensor = tf.convert_to_tensor(data_c.values, dtype=tf.float32) # Specify the correct dtype

new_sample_tensor

# data_c=np.array([26,    0.0,    0.0,    0.0,    1,      3.0,    4.0,    1,      3.0,    7.0,    2,      32,     1])
new_sample_tensor = tf.convert_to_tensor(data_c.values, dtype=tf.float32)

best_model= tf.keras.models.load_model('/content/drive/MyDrive/Project-5-Predict-depression/model.keras')
ts_predict= best_model.predict(new_sample_tensor)
ts_predict.round().astype(int).flatten()

ts_predict.round().astype(int).flatten()[0]



"""# **Streamlit App**"""

!pip install streamlit pyngrok

from pyngrok import ngrok
ngrok.set_auth_token("30KwR5ga0Vn9OtYNtI04zeZnnVL_6MiSjKv2387sQbijjpHSS")

import shutil

src_path = "/content/drive/MyDrive/Project-5-Predict-depression/model.keras"
dst_path = "/content/model.keras"

shutil.copy(src_path, dst_path)
print("✅ Model copied to /content/")

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import streamlit as st
# import os
# import pandas as pd
# import numpy as np
# import tensorflow as tf
# from sklearn.preprocessing import LabelEncoder, MinMaxScaler
# 
# # ----------------- Prediction Class -----------------
# class Prediction:
#     def __init__(self, df):
#         self.df = df
#         self.encoders = {}  # store separate encoders
#         self.scaler = None
# 
#     def Grouping_degree(self, degree, df):
#         for i in degree:
#             if isinstance(i, str):
#                 if i.startswith('B') or i == 'MBBS' or i == 'LLB':
#                     df['Degree'] = df['Degree'].replace(i, 'Bachelors')
#                 elif i.startswith('M') or i == 'LLM':
#                     df['Degree'] = df['Degree'].replace(i, 'Masters')
#                 elif i.startswith('P'):
#                     df['Degree'] = df['Degree'].replace(i, 'Doctorate')
#         return df
# 
#     def clean_data(self, df):
#         drop_cols = [c for c in ['id', 'Name'] if c in df.columns]
#         df.drop(drop_cols, axis=1, inplace=True, errors="ignore")
# 
#         num_fill = {
#             'Academic Pressure': 0.0, 'Work Pressure': 0.0, 'CGPA': 0.0,
#             'Study Satisfaction': 0.0, 'Job Satisfaction': 0.0, 'Financial Stress': 0.0
#         }
#         for col, val in num_fill.items():
#             if col in df.columns:
#                 df[col] = df[col].fillna(val)
# 
#         if "Dietary Habits" in df.columns:
#             df['Dietary Habits'] = df['Dietary Habits'].replace(
#                 ['Less than Healthy', 'No Healthy', 'Less Healthy'], 'Unhealthy')
#             df['Dietary Habits'] = df['Dietary Habits'].replace('More Healthy', 'Healthy')
#             df['Dietary Habits'] = df['Dietary Habits'].apply(
#                 lambda x: x if x in ['Healthy', 'Unhealthy', 'Moderate'] else 'Other')
# 
#         if "Degree" in df.columns:
#             df['Degree'] = df['Degree'].fillna('Other')
#             degree = list(df['Degree'].unique())
#             df = self.Grouping_degree(degree, df)
# 
#         if "Profession" in df.columns:
#             df['Profession'] = df['Profession'].fillna('Other')
#             df['Profession'] = df['Profession'].replace({
#                 'City Manager': 'Manager', 'Dev': 'Software Engineer',
#                 'Medical Doctor': 'Doctor', 'Finanancial Analyst': 'Financial Analyst'
#             })
# 
#         return df
# 
#     def Preprocess(self):
#         tr_data = pd.read_csv(
#             "https://raw.githubusercontent.com/amoghchetty/predicting-despression-via-deep-learning-/refs/heads/main/train.csv"
#         )
#         tr_data = self.clean_data(tr_data)
#         self.df = self.clean_data(self.df)
# 
#         mapping_degree = {'Other': 0, 'Class 12': 1, "Bachelors": 2, "Masters": 3, "Doctorate": 4}
#         mapping_diet = {'Other': 0, 'Healthy': 3, 'Unhealthy': 1, 'Moderate': 2}
# 
#         if "Degree" in self.df.columns:
#             self.df['Degree'] = self.df['Degree'].map(mapping_degree).fillna(0)
#         if "Dietary Habits" in self.df.columns:
#             self.df['Dietary Habits'] = self.df['Dietary Habits'].map(mapping_diet).fillna(0)
# 
#         tr_data['Degree'] = tr_data['Degree'].map(mapping_degree).fillna(0)
#         tr_data['Dietary Habits'] = tr_data['Dietary Habits'].map(mapping_diet).fillna(0)
# 
#         cat_cols = tr_data.select_dtypes(include="object").columns.to_list()
#         for col in cat_cols:
#             le = LabelEncoder()
#             tr_data[col] = tr_data[col].astype(str)
#             self.df[col] = self.df[col].astype(str)
# 
#             tr_data[col] = le.fit_transform(tr_data[col])
#             self.df[col] = self.df[col].map(
#                 lambda x: le.transform([x])[0] if x in le.classes_ else -1
#             )
#             self.df[col] = self.df[col].replace(-1, 0)
#             self.encoders[col] = le
# 
#         num_col = ['Age', 'Academic Pressure', 'Work Pressure', 'CGPA',
#                    'Study Satisfaction', 'Job Satisfaction',
#                    'Work/Study Hours', 'Financial Stress']
# 
#         self.scaler = MinMaxScaler()
#         tr_data[num_col] = self.scaler.fit_transform(tr_data[num_col])
#         self.df[num_col] = self.df[num_col].fillna(0)
#         self.df[num_col] = self.scaler.transform(self.df[num_col])
# 
#         return self.df
# 
# # ----------------- Load Model -----------------
# base_dir = os.path.dirname(os.path.abspath(__file__))
# model_path = os.path.join(base_dir, "model.keras")
# best_model = tf.keras.models.load_model(model_path)
# 
# # ----------------- Sidebar Navigation -----------------
# st.sidebar.title("Navigation")
# page = st.sidebar.radio("Go to", ["Project Introduction", "Mental Health Prediction", "Creator Info"])
# 
# # ----------------- Page 1: Project Introduction -----------------
# if page == "Project Introduction":
#     st.title(" Mental Health Prediction Project")
#     st.markdown("""
#     Welcome to the **Mental Health Prediction App**!
#     This project uses **Machine Learning** to analyze various lifestyle, academic, and personal factors
#     to predict whether a person may be experiencing mental health challenges.
# 
#     ### Objectives:
#     - Help spread awareness about mental health.
#     - Provide an easy-to-use interface for predictions.
#     - Encourage users to take care of their well-being.
# 
#      **Disclaimer**: This tool is for educational and awareness purposes only.
#     It is **not a substitute** for professional medical advice.
#     """)
# 
# # ----------------- Page 2: Prediction -----------------
# elif page == "Mental Health Prediction":
#     st.title(" Mental Health Prediction")
# 
#     name = st.text_input("Enter your Name")
#     gen = st.selectbox("Select your Gender", ('Male', 'Female'))
#     age = st.number_input("Enter your Age", min_value=1, max_value=100, step=1)
#     city_options = [
#         "Ahmedabad", "Bangalore", "Chennai", "Delhi", "Hyderabad",
#         "Kolkata", "Mumbai", "Pune", "Other"
#     ]
#     city = st.selectbox("Select your City", city_options)
#     role = st.selectbox("Select your role", ("Working Professional", "Student"))
#     prof = st.text_input("Enter your Profession")
#     acpres = st.selectbox("Rate your Academic Pressure", (0, 1, 2, 3, 4, 5))
#     wkpres = st.selectbox("Rate your Work Pressure", (0, 1, 2, 3, 4, 5))
#     cgpa = st.number_input("Enter your CGPA", min_value=0.0, max_value=10.0, step=0.1)
#     ssat = st.selectbox("Rate your Study Satisfaction", (0, 1, 2, 3, 4, 5))
#     jsat = st.selectbox("Rate your Job Satisfaction", (0, 1, 2, 3, 4, 5))
#     sleepdur = st.text_input("Enter your Sleep Duration")
#     diet = st.selectbox("Select your Dietary Habits", ('Healthy', 'Unhealthy', 'Moderate'))
#     deg = st.text_input("Enter your Degree")
#     suicide = st.selectbox("Have you ever had suicidal thoughts ?", ('No', 'Yes'))
#     hrs = st.number_input("Enter your Work/Study Hours", min_value=0, max_value=24, step=1)
#     fstress = st.selectbox("Rate your Financial Stress", (0, 1, 2, 3, 4, 5))
#     fhis = st.selectbox("Family History of Mental Illness", ('No', 'Yes'))
# 
#     if 'clicked' not in st.session_state:
#         st.session_state.clicked = False
# 
#     def click_button():
#         st.session_state.clicked = True
# 
#     st.button('Submit', on_click=click_button)
# 
#     if st.session_state.clicked:
#         try:
#             data = pd.DataFrame([{
#                 'Name': name, 'Gender': gen, 'Age': age,
#                 'City': city, 'Working Professional or Student': role,
#                 'Profession': prof, 'Academic Pressure': acpres, 'Work Pressure': wkpres,
#                 'CGPA': cgpa, 'Study Satisfaction': ssat, 'Job Satisfaction': jsat,
#                 'Sleep Duration': sleepdur, 'Dietary Habits': diet, 'Degree': deg,
#                 "Have you ever had suicidal thoughts ?": suicide,
#                 'Work/Study Hours': hrs, 'Financial Stress': fstress,
#                 'Family History of Mental Illness': fhis
#             }])
# 
#             pred = Prediction(data)
#             data_c = pred.Preprocess()
#             new_sample_tensor = tf.convert_to_tensor(data_c.values, dtype=tf.float32)
# 
#             ts_predict = best_model.predict(new_sample_tensor)
# 
#             if ts_predict.shape[-1] == 1:
#                 ts_pred = int(ts_predict.round().flatten()[0])
#             else:
#                 ts_pred = int(np.argmax(ts_predict, axis=-1)[0])
#             pred_label = "Yes" if ts_pred == 1 else "No"
# 
#             st.success(f"{name}, prediction: {pred_label}")
# 
#             if ts_pred == 0:
#                 st.subheader(f"**Great {name}! You seem mentally healthy and doing well. Keep it up! **")
#             elif ts_pred == 1:
#                 st.subheader(f"**{name}, it looks like you may be experiencing some challenges. "
#                              f"Remember, it's okay to seek support and take care of yourself **")
#             else:
#                 st.subheader(f"**{name}, we couldn’t confidently interpret your results. "
#                              f"Try again or consult a professional for clarity.**")
# 
#         except Exception as e:
#             st.error(f" Prediction failed: {e}")
#             st.write("Debugging info:", data)
# 
# # ----------------- Page 3: Creator Info -----------------
# elif page == "Creator Info":
#     st.title(" Creator Information")
#     st.markdown("""
#     **Created By:** Amogh Chetty
# 
#     - Course: Data science
#     - Interests: Deep Learning
# 
#     This app was developed as part of a **Deep Learning Project**
#     to raise awareness about mental health through technology.
# 
#     """)
# 
#

import subprocess
from pyngrok import ngrok

ngrok.set_auth_token("30KwR5ga0Vn9OtYNtI04zeZnnVL_6MiSjKv2387sQbijjpHSS")

# Open tunnel on port 8501
public_url = ngrok.connect(8501)
print("Streamlit app is live at:", public_url)

# Run Streamlit in background
process = subprocess.Popen(["streamlit", "run", "app.py", "--server.port", "8501"])



